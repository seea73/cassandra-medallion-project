{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install Cassandra Python driver\n",
        "!pip install cassandra-driver pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqGVCDl5apUc",
        "outputId": "a4c923f5-2b14-417e-eea3-393a44a75b9b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cassandra-driver in /usr/local/lib/python3.11/dist-packages (3.29.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: geomet<0.3,>=0.1 in /usr/local/lib/python3.11/dist-packages (from cassandra-driver) (0.2.1.post1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.1.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "import uuid\n",
        "\n",
        "cloud_config = {\n",
        "    'secure_connect_bundle': 'secure-connect-sales-db.zip'\n",
        "}\n",
        "\n",
        "with open(\"token.json\") as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "CLIENT_ID = secrets[\"clientId\"]\n",
        "CLIENT_SECRET = secrets[\"secret\"]\n",
        "\n",
        "auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect()\n",
        "\n",
        "if session:\n",
        "    print('Connected!')\n",
        "else:\n",
        "    print(\"An error occurred.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2jh6jU_atIA",
        "outputId": "c485b6a0-56f8-4c3d-ffcf-44a698d96049"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for e635bc2e-25a7-4108-a1b2-f6c68c871c62-us-east-2.db.astra.datastax.com:29042:0750e59f-441b-37bb-b0a7-e097c5d725f7. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for e635bc2e-25a7-4108-a1b2-f6c68c871c62-us-east-2.db.astra.datastax.com:29042:0750e59f-441b-37bb-b0a7-e097c5d725f7. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for e635bc2e-25a7-4108-a1b2-f6c68c871c62-us-east-2.db.astra.datastax.com:29042:0750e59f-441b-37bb-b0a7-e097c5d725f7. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Download the sample data\n",
        "!wget https://raw.githubusercontent.com/gchandra10/filestorage/main/sales_100.csv\n",
        "\n",
        "# Load the data into a pandas DataFrame\n",
        "sales_df = pd.read_csv('sales_100.csv')\n",
        "\n",
        "# Display the first few rows to understand the data\n",
        "print(sales_df.head())\n",
        "\n",
        "# Check data types and null values\n",
        "print(sales_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1w3zZ8La3f8",
        "outputId": "4f33091b-406e-4390-b2be-b44977b05bd3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-10 02:43:17--  https://raw.githubusercontent.com/gchandra10/filestorage/main/sales_100.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12309 (12K) [text/plain]\n",
            "Saving to: ‘sales_100.csv.3’\n",
            "\n",
            "\rsales_100.csv.3       0%[                    ]       0  --.-KB/s               \rsales_100.csv.3     100%[===================>]  12.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-04-10 02:43:17 (74.1 MB/s) - ‘sales_100.csv.3’ saved [12309/12309]\n",
            "\n",
            "                         Region           Country  Item Type Sales Channel  \\\n",
            "0            Sub-Saharan Africa      South Africa     Fruits       Offline   \n",
            "1  Middle East and North Africa           Morocco    Clothes        Online   \n",
            "2         Australia and Oceania  Papua New Guinea       Meat       Offline   \n",
            "3            Sub-Saharan Africa          Djibouti    Clothes       Offline   \n",
            "4                        Europe          Slovakia  Beverages       Offline   \n",
            "\n",
            "  Order Priority  Order Date   Order ID   Ship Date  UnitsSold  UnitPrice  \\\n",
            "0              M   7/27/2012  443368995   7/28/2012       1593       9.33   \n",
            "1              M   9/14/2013  667593514  10/19/2013       4611     109.28   \n",
            "2              M   5/15/2015  940995585    6/4/2015        360     421.89   \n",
            "3              H   5/17/2017  880811536    7/2/2017        562     109.28   \n",
            "4              L  10/26/2016  174590194   12/4/2016       3973      47.45   \n",
            "\n",
            "   UnitCost  TotalRevenue  TotalCost  TotalProfit  \n",
            "0      6.92      14862.69   11023.56      3839.13  \n",
            "1     35.84     503890.08  165258.24    338631.84  \n",
            "2    364.69     151880.40  131288.40     20592.00  \n",
            "3     35.84      61415.36   20142.08     41273.28  \n",
            "4     31.79     188518.85  126301.67     62217.18  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 99 entries, 0 to 98\n",
            "Data columns (total 14 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   Region          99 non-null     object \n",
            " 1   Country         99 non-null     object \n",
            " 2   Item Type       99 non-null     object \n",
            " 3   Sales Channel   99 non-null     object \n",
            " 4   Order Priority  99 non-null     object \n",
            " 5   Order Date      99 non-null     object \n",
            " 6   Order ID        99 non-null     int64  \n",
            " 7   Ship Date       99 non-null     object \n",
            " 8   UnitsSold       99 non-null     int64  \n",
            " 9   UnitPrice       99 non-null     float64\n",
            " 10  UnitCost        99 non-null     float64\n",
            " 11  TotalRevenue    99 non-null     float64\n",
            " 12  TotalCost       99 non-null     float64\n",
            " 13  TotalProfit     99 non-null     float64\n",
            "dtypes: float64(5), int64(2), object(7)\n",
            "memory usage: 11.0+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAvailable keyspaces in your Astra DB:\")\n",
        "keyspaces = session.execute(\"SELECT keyspace_name FROM system_schema.keyspaces\")\n",
        "for keyspace in keyspaces:\n",
        "    print(f\"- {keyspace.keyspace_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mz0dBCza612",
        "outputId": "ee87b47d-ff22-48b1-ff58-8f58e3196a96"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Available keyspaces in your Astra DB:\n",
            "- system_auth\n",
            "- system_schema\n",
            "- datastax_sla\n",
            "- sales_ks\n",
            "- system\n",
            "- default_keyspace\n",
            "- data_endpoint_auth\n",
            "- system_traces\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask user to choose a keyspace from the available ones\n",
        "print(\"\\nPlease enter the name of your keyspace to use:\")\n",
        "keyspace_name = input()\n",
        "\n",
        "# Use the selected keyspace\n",
        "session.set_keyspace(keyspace_name)\n",
        "print(f\"Connected to keyspace {keyspace_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX2wSIqedFKA",
        "outputId": "19ee822d-228e-4ab8-9878-e83e6430ad2a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Please enter the name of your keyspace to use:\n",
            "sales_ks\n",
            "Connected to keyspace sales_ks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 5: Create Bronze Level Table (Raw Data)\n",
        "print(\"\\nCreating Bronze level table...\")\n",
        "bronze_table_name = 'bronze_sales'\n",
        "\n",
        "# Check data types from the DataFrame to create appropriate CQL types\n",
        "column_types = {}\n",
        "for column in sales_df.columns:\n",
        "    if sales_df[column].dtype == 'int64':\n",
        "        column_types[column] = 'int'\n",
        "    elif sales_df[column].dtype == 'float64':\n",
        "        column_types[column] = 'double'\n",
        "    else:\n",
        "        column_types[column] = 'text'\n",
        "\n",
        "# Drop table if exists (for clean development)\n",
        "session.execute(f\"DROP TABLE IF EXISTS {bronze_table_name}\")\n",
        "\n",
        "# Create the Bronze table\n",
        "create_bronze_table_query = f\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS {bronze_table_name} (\n",
        "    id uuid PRIMARY KEY,\n",
        "    ingestion_time timestamp,\n",
        "    \"\"\"\n",
        "\n",
        "for col, col_type in column_types.items():\n",
        "    # Replace spaces in column names with underscores and make lowercase\n",
        "    col_cql = col.replace(' ', '_').lower()\n",
        "    create_bronze_table_query += f\"{col_cql} {col_type},\\n    \"\n",
        "\n",
        "# Remove trailing comma and newline, then close the query\n",
        "create_bronze_table_query = create_bronze_table_query[:-6] + \"\\n)\"\n",
        "\n",
        "# Execute the create table query\n",
        "session.execute(create_bronze_table_query)\n",
        "print(f\"Created Bronze table: {bronze_table_name}\")\n",
        "\n",
        "# Prepare batch statements for Bronze table\n",
        "print(\"Loading data into Bronze table...\")\n",
        "for _, row in sales_df.iterrows():\n",
        "    # Create unique ID for this record\n",
        "    record_id = uuid.uuid4()\n",
        "\n",
        "    # Build the insert query\n",
        "    columns = ['id', 'ingestion_time']\n",
        "    values = [str(record_id), 'toTimestamp(now())']\n",
        "\n",
        "    for col in sales_df.columns:\n",
        "        # Clean column name for CQL\n",
        "        col_cql = col.replace(' ', '_').lower()\n",
        "        columns.append(col_cql)\n",
        "\n",
        "        # Format value based on type\n",
        "        if pd.isna(row[col]):\n",
        "            values.append('null')\n",
        "        elif isinstance(row[col], (int, float)):\n",
        "            values.append(str(row[col]))\n",
        "        else:\n",
        "            escaped = str(row[col]).replace(\"'\", \"''\")\n",
        "            values.append(f\"'{escaped}'\")\n",
        "\n",
        "    insert_query = f\"\"\"\n",
        "    INSERT INTO {bronze_table_name} ({', '.join(columns)})\n",
        "    VALUES ({', '.join(values)})\n",
        "    \"\"\"\n",
        "    session.execute(insert_query)\n",
        "\n",
        "print(f\"Data loaded into Bronze table: {bronze_table_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5LhaZ_pdMli",
        "outputId": "c6beb7b4-dafc-404e-9c7d-4f22906ea23a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating Bronze level table...\n",
            "Created Bronze table: bronze_sales\n",
            "Loading data into Bronze table...\n",
            "Data loaded into Bronze table: bronze_sales\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Create Silver Level Table (Cleaned Data)\n",
        "print(\"\\nCreating Silver level table...\")\n",
        "silver_table_name = 'silver_sales'\n",
        "\n",
        "# Drop table if exists (for clean development)\n",
        "session.execute(f\"DROP TABLE IF EXISTS {silver_table_name}\")\n",
        "\n",
        "# Define the create table query for Silver layer\n",
        "create_silver_table_query = f\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS {silver_table_name} (\n",
        "    id uuid PRIMARY KEY,\n",
        "    processing_time timestamp,\n",
        "    order_date date,\n",
        "    region text,\n",
        "    country text,\n",
        "    item_type text,\n",
        "    sales_channel text,\n",
        "    order_priority text,\n",
        "    order_id text,\n",
        "    ship_date date,\n",
        "    units_sold int,\n",
        "    unit_price double,\n",
        "    unit_cost double,\n",
        "    total_revenue double,\n",
        "    total_cost double,\n",
        "    total_profit double\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "# Execute the create table query\n",
        "session.execute(create_silver_table_query)\n",
        "print(f\"Created Silver table: {silver_table_name}\")\n",
        "\n",
        "# Get data from Bronze table to process\n",
        "rows = session.execute(f\"SELECT * FROM {bronze_table_name}\")\n",
        "\n",
        "# Process and insert data into Silver table\n",
        "print(\"Processing data for Silver table...\")\n",
        "for row in rows:\n",
        "    try:\n",
        "        # Handle date conversions - assuming dates are in format MM/DD/YYYY\n",
        "        if hasattr(row, 'order_date') and row.order_date:\n",
        "            date_parts = row.order_date.split('/')\n",
        "            if len(date_parts) == 3:\n",
        "                month, day, year = date_parts\n",
        "                order_date = f\"'{year}-{month.zfill(2)}-{day.zfill(2)}'\"\n",
        "            else:\n",
        "                order_date = 'null'\n",
        "        else:\n",
        "            order_date = 'null'\n",
        "\n",
        "        if hasattr(row, 'ship_date') and row.ship_date:\n",
        "            date_parts = row.ship_date.split('/')\n",
        "            if len(date_parts) == 3:\n",
        "                month, day, year = date_parts\n",
        "                ship_date = f\"'{year}-{month.zfill(2)}-{day.zfill(2)}'\"\n",
        "            else:\n",
        "                ship_date = 'null'\n",
        "        else:\n",
        "            ship_date = 'null'\n",
        "\n",
        "        # Ensure numeric values are proper\n",
        "        units_sold = row.units_sold if hasattr(row, 'units_sold') and row.units_sold is not None else 0\n",
        "        unit_price = row.unit_price if hasattr(row, 'unit_price') and row.unit_price is not None else 0.0\n",
        "        unit_cost = row.unit_cost if hasattr(row, 'unit_cost') and row.unit_cost is not None else 0.0\n",
        "\n",
        "        # Calculate derived fields\n",
        "        total_revenue = units_sold * unit_price\n",
        "        total_cost = units_sold * unit_cost\n",
        "        total_profit = total_revenue - total_cost\n",
        "\n",
        "        # Insert into Silver table\n",
        "        insert_query = f\"\"\"\n",
        "        INSERT INTO {silver_table_name} (\n",
        "            id, processing_time, order_date, region, country, item_type,\n",
        "            sales_channel, order_priority, order_id, ship_date,\n",
        "            units_sold, unit_price, unit_cost, total_revenue, total_cost, total_profit\n",
        "        )\n",
        "        VALUES (\n",
        "            {row.id}, toTimestamp(now()), {order_date},\n",
        "            '{row.region if hasattr(row, 'region') and row.region else \"Unknown\"}',\n",
        "            '{row.country if hasattr(row, 'country') and row.country else \"Unknown\"}',\n",
        "            '{row.item_type if hasattr(row, 'item_type') and row.item_type else \"Unknown\"}',\n",
        "            '{row.sales_channel if hasattr(row, 'sales_channel') and row.sales_channel else \"Unknown\"}',\n",
        "            '{row.order_priority if hasattr(row, 'order_priority') and row.order_priority else \"Unknown\"}',\n",
        "            '{row.order_id if hasattr(row, 'order_id') and row.order_id else \"Unknown\"}',\n",
        "            {ship_date}, {units_sold}, {unit_price}, {unit_cost},\n",
        "            {total_revenue}, {total_cost}, {total_profit}\n",
        "        )\n",
        "        \"\"\"\n",
        "        session.execute(insert_query)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing row: {e}\")\n",
        "\n",
        "print(f\"Data processed and loaded into Silver table: {silver_table_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ybviDmNhRn5",
        "outputId": "6f9ce9a9-b56e-4956-cb1c-291d08d1cb1c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating Silver level table...\n",
            "Created Silver table: silver_sales\n",
            "Processing data for Silver table...\n",
            "Data processed and loaded into Silver table: silver_sales\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Create Gold Level Tables (Business Views)\n",
        "print(\"\\nCreating Gold level tables...\")\n",
        "\n",
        "# Gold Table 1: Sales by Region\n",
        "gold_region_table = 'gold_sales_by_region'\n",
        "\n",
        "# Drop table if exists (for clean development)\n",
        "session.execute(f\"DROP TABLE IF EXISTS {gold_region_table}\")\n",
        "\n",
        "create_gold_region_query = f\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS {gold_region_table} (\n",
        "    region text,\n",
        "    report_date date,\n",
        "    total_orders int,\n",
        "    total_revenue double,\n",
        "    total_profit double,\n",
        "    avg_order_value double,\n",
        "    PRIMARY KEY (region, report_date)\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "session.execute(create_gold_region_query)\n",
        "print(f\"Created Gold table: {gold_region_table}\")\n",
        "\n",
        "# Aggregate data by region and load into Gold table\n",
        "print(\"Processing data for Gold Sales by Region table...\")\n",
        "try:\n",
        "    # In Cassandra, we can't directly do this aggregation in CQL, so we'll fetch and process in Python\n",
        "    silver_data = session.execute(f\"SELECT * FROM {silver_table_name}\")\n",
        "\n",
        "    # Process data in Python\n",
        "    region_aggregations = {}\n",
        "    for row in silver_data:\n",
        "        region = row.region\n",
        "        if region not in region_aggregations:\n",
        "            region_aggregations[region] = {\n",
        "                'total_orders': 0,\n",
        "                'total_revenue': 0,\n",
        "                'total_profit': 0\n",
        "            }\n",
        "\n",
        "        region_aggregations[region]['total_orders'] += 1\n",
        "        region_aggregations[region]['total_revenue'] += row.total_revenue\n",
        "        region_aggregations[region]['total_profit'] += row.total_profit\n",
        "\n",
        "    # Insert aggregated data\n",
        "    for region, data in region_aggregations.items():\n",
        "        avg_order_value = data['total_revenue'] / data['total_orders'] if data['total_orders'] > 0 else 0\n",
        "\n",
        "        insert_query = f\"\"\"\n",
        "        INSERT INTO {gold_region_table} (\n",
        "            region, report_date, total_orders,\n",
        "            total_revenue, total_profit, avg_order_value\n",
        "        )\n",
        "        VALUES (\n",
        "            '{region}', toDate(now()), {data['total_orders']},\n",
        "            {data['total_revenue']}, {data['total_profit']}, {avg_order_value}\n",
        "        )\n",
        "        \"\"\"\n",
        "        session.execute(insert_query)\n",
        "\n",
        "    print(f\"Aggregated data loaded into Gold table: {gold_region_table}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error aggregating by region: {e}\")\n",
        "\n",
        "# Gold Table 2: Sales by Item Type\n",
        "gold_item_table = 'gold_sales_by_item_type'\n",
        "\n",
        "# Drop table if exists (for clean development)\n",
        "session.execute(f\"DROP TABLE IF EXISTS {gold_item_table}\")\n",
        "\n",
        "create_gold_item_query = f\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS {gold_item_table} (\n",
        "    item_type text,\n",
        "    report_date date,\n",
        "    total_units_sold int,\n",
        "    total_revenue double,\n",
        "    total_profit double,\n",
        "    profit_margin double,\n",
        "    PRIMARY KEY (item_type, report_date)\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "session.execute(create_gold_item_query)\n",
        "print(f\"Created Gold table: {gold_item_table}\")\n",
        "\n",
        "# Process and aggregate data by item_type\n",
        "print(\"Processing data for Gold Sales by Item Type table...\")\n",
        "try:\n",
        "    silver_data = session.execute(f\"SELECT * FROM {silver_table_name}\")\n",
        "\n",
        "    item_aggregations = {}\n",
        "    for row in silver_data:\n",
        "        item_type = row.item_type\n",
        "        if item_type not in item_aggregations:\n",
        "            item_aggregations[item_type] = {\n",
        "                'total_units_sold': 0,\n",
        "                'total_revenue': 0,\n",
        "                'total_profit': 0\n",
        "            }\n",
        "\n",
        "        item_aggregations[item_type]['total_units_sold'] += row.units_sold\n",
        "        item_aggregations[item_type]['total_revenue'] += row.total_revenue\n",
        "        item_aggregations[item_type]['total_profit'] += row.total_profit\n",
        "\n",
        "    # Insert aggregated data\n",
        "    for item_type, data in item_aggregations.items():\n",
        "        profit_margin = (data['total_profit'] / data['total_revenue'] * 100) if data['total_revenue'] > 0 else 0\n",
        "\n",
        "        insert_query = f\"\"\"\n",
        "        INSERT INTO {gold_item_table} (\n",
        "            item_type, report_date, total_units_sold,\n",
        "            total_revenue, total_profit, profit_margin\n",
        "        )\n",
        "        VALUES (\n",
        "            '{item_type}', toDate(now()), {data['total_units_sold']},\n",
        "            {data['total_revenue']}, {data['total_profit']}, {profit_margin}\n",
        "        )\n",
        "        \"\"\"\n",
        "        session.execute(insert_query)\n",
        "\n",
        "    print(f\"Aggregated data loaded into Gold table: {gold_item_table}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error aggregating by item_type: {e}\")\n",
        "\n",
        "# Gold Table 3: Sales Performance by Sales Channel\n",
        "gold_channel_table = 'gold_sales_by_channel'\n",
        "\n",
        "# Drop table if exists (for clean development)\n",
        "session.execute(f\"DROP TABLE IF EXISTS {gold_channel_table}\")\n",
        "\n",
        "create_gold_channel_query = f\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS {gold_channel_table} (\n",
        "    sales_channel text,\n",
        "    report_date date,\n",
        "    total_orders int,\n",
        "    total_revenue double,\n",
        "    total_profit double,\n",
        "    avg_order_priority text,\n",
        "    PRIMARY KEY (sales_channel, report_date)\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "session.execute(create_gold_channel_query)\n",
        "print(f\"Created Gold table: {gold_channel_table}\")\n",
        "\n",
        "# Process and aggregate data by sales_channel\n",
        "print(\"Processing data for Gold Sales by Channel table...\")\n",
        "try:\n",
        "    silver_data = session.execute(f\"SELECT * FROM {silver_table_name}\")\n",
        "\n",
        "    channel_aggregations = {}\n",
        "    priority_counts = {}\n",
        "\n",
        "    for row in silver_data:\n",
        "        channel = row.sales_channel\n",
        "        if channel not in channel_aggregations:\n",
        "            channel_aggregations[channel] = {\n",
        "                'total_orders': 0,\n",
        "                'total_revenue': 0,\n",
        "                'total_profit': 0\n",
        "            }\n",
        "            priority_counts[channel] = {}\n",
        "\n",
        "        channel_aggregations[channel]['total_orders'] += 1\n",
        "        channel_aggregations[channel]['total_revenue'] += row.total_revenue\n",
        "        channel_aggregations[channel]['total_profit'] += row.total_profit\n",
        "\n",
        "        # Track order priorities\n",
        "        priority = row.order_priority\n",
        "        if priority not in priority_counts[channel]:\n",
        "            priority_counts[channel][priority] = 0\n",
        "        priority_counts[channel][priority] += 1\n",
        "\n",
        "    # Insert aggregated data\n",
        "    for channel, data in channel_aggregations.items():\n",
        "        # Find most common priority\n",
        "        max_priority = None\n",
        "        max_count = 0\n",
        "        for priority, count in priority_counts[channel].items():\n",
        "            if count > max_count:\n",
        "                max_count = count\n",
        "                max_priority = priority\n",
        "\n",
        "        insert_query = f\"\"\"\n",
        "        INSERT INTO {gold_channel_table} (\n",
        "            sales_channel, report_date, total_orders,\n",
        "            total_revenue, total_profit, avg_order_priority\n",
        "        )\n",
        "        VALUES (\n",
        "            '{channel}', toDate(now()), {data['total_orders']},\n",
        "            {data['total_revenue']}, {data['total_profit']}, '{max_priority}'\n",
        "        )\n",
        "        \"\"\"\n",
        "        session.execute(insert_query)\n",
        "\n",
        "    print(f\"Aggregated data loaded into Gold table: {gold_channel_table}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error aggregating by sales_channel: {e}\")\n",
        "\n",
        "# Step 8: Query the gold tables to display and screenshot the results\n",
        "print(\"\\n--- GOLD TABLE RESULTS ---\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRsyNQWUhijw",
        "outputId": "add26c9e-20a6-4ac4-e63b-d22c36f268f0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating Gold level tables...\n",
            "Created Gold table: gold_sales_by_region\n",
            "Processing data for Gold Sales by Region table...\n",
            "Aggregated data loaded into Gold table: gold_sales_by_region\n",
            "Created Gold table: gold_sales_by_item_type\n",
            "Processing data for Gold Sales by Item Type table...\n",
            "Aggregated data loaded into Gold table: gold_sales_by_item_type\n",
            "Created Gold table: gold_sales_by_channel\n",
            "Processing data for Gold Sales by Channel table...\n",
            "Aggregated data loaded into Gold table: gold_sales_by_channel\n",
            "\n",
            "--- GOLD TABLE RESULTS ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nGold Sales by Region data:\")\n",
        "gold_region_data = session.execute(f\"SELECT * FROM {gold_region_table}\")\n",
        "for row in gold_region_data:\n",
        "    print(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKHWo-Rileky",
        "outputId": "963ea36a-5748-4d97-8647-a08b9a0226cb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gold Sales by Region data:\n",
            "Row(region='Australia and Oceania', report_date=Date(20188), avg_order_value=0.0, total_orders=9, total_profit=0.0, total_revenue=0.0)\n",
            "Row(region='Europe', report_date=Date(20188), avg_order_value=0.0, total_orders=24, total_profit=0.0, total_revenue=0.0)\n",
            "Row(region='Middle East and North Africa', report_date=Date(20188), avg_order_value=0.0, total_orders=10, total_profit=0.0, total_revenue=0.0)\n",
            "Row(region='Central America and the Caribbean', report_date=Date(20188), avg_order_value=0.0, total_orders=11, total_profit=0.0, total_revenue=0.0)\n",
            "Row(region='Asia', report_date=Date(20188), avg_order_value=0.0, total_orders=19, total_profit=0.0, total_revenue=0.0)\n",
            "Row(region='Sub-Saharan Africa', report_date=Date(20188), avg_order_value=0.0, total_orders=24, total_profit=0.0, total_revenue=0.0)\n",
            "Row(region='North America', report_date=Date(20188), avg_order_value=0.0, total_orders=2, total_profit=0.0, total_revenue=0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nGold Sales by Item Type data:\")\n",
        "gold_item_data = session.execute(f\"SELECT * FROM {gold_item_table}\")\n",
        "for row in gold_item_data:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynKsYVPek0JX",
        "outputId": "51c9bfa0-75e9-4eed-8945-c11e337beb2b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gold Sales by Item Type data:\n",
            "Row(item_type='Household', report_date=Date(20188), profit_margin=0.0, total_profit=0.0, total_revenue=0.0, total_units_sold=0)\n",
            "Row(item_type='Office Supplies', report_date=Date(20188), profit_margin=0.0, total_profit=0.0, total_revenue=0.0, total_units_sold=0)\n",
            "Row(item_type='Vegetables', report_date=Date(20188), profit_margin=0.0, total_profit=0.0, total_revenue=0.0, total_units_sold=0)\n",
            "Row(item_type='Snacks', report_date=Date(20188), profit_margin=0.0, total_profit=0.0, total_revenue=0.0, total_units_sold=0)\n",
            "Row(item_type='Personal Care', report_date=Date(20188), profit_margin=0.0, total_profit=0.0, total_revenue=0.0, total_units_sold=0)\n",
            "Row(item_type='Meat', report_date=Date(20188), profit_margin=0.0, total_profit=0.0, total_revenue=0.0, total_units_sold=0)\n",
            "Row(item_type='Fruits', report_date=Date(20188), profit_margin=0.0, total_profit=0.0, total_revenue=0.0, total_units_sold=0)\n",
            "Row(item_type='Beverages', report_date=Date(20188), profit_margin=0.0, total_profit=0.0, total_revenue=0.0, total_units_sold=0)\n",
            "Row(item_type='Cereal', report_date=Date(20188), profit_margin=0.0, total_profit=0.0, total_revenue=0.0, total_units_sold=0)\n",
            "Row(item_type='Cosmetics', report_date=Date(20188), profit_margin=0.0, total_profit=0.0, total_revenue=0.0, total_units_sold=0)\n",
            "Row(item_type='Baby Food', report_date=Date(20188), profit_margin=0.0, total_profit=0.0, total_revenue=0.0, total_units_sold=0)\n",
            "Row(item_type='Clothes', report_date=Date(20188), profit_margin=0.0, total_profit=0.0, total_revenue=0.0, total_units_sold=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nGold Sales by Channel data:\")\n",
        "gold_channel_data = session.execute(f\"SELECT * FROM {gold_channel_table}\")\n",
        "for row in gold_channel_data:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swR9x7HSk0zF",
        "outputId": "816ce55d-31ad-4da1-f8e7-85f1e545e762"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gold Sales by Channel data:\n",
            "Row(sales_channel='Online', report_date=Date(20188), avg_order_priority='M', total_orders=59, total_profit=0.0, total_revenue=0.0)\n",
            "Row(sales_channel='Offline', report_date=Date(20188), avg_order_priority='M', total_orders=40, total_profit=0.0, total_revenue=0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Close the connection\n",
        "cluster.shutdown()\n",
        "print(\"\\nCassandra connection closed. Process complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFCRmpSah75q",
        "outputId": "152891e4-1875-42ea-e968-d600c8b752ee"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cassandra connection closed. Process complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VFIrouA_eO2t"
      }
    }
  ]
}